{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "august-kernel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GMGPJ\\Anaconda3\\envs\\sentiment_analysis_test\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pythainlp\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.util.normalize import normalize, remove_tonemark\n",
    "from pythainlp.ulmfit.preprocess import (\n",
    "    fix_html,\n",
    "    lowercase_all,\n",
    "    replace_rep_nonum,\n",
    "    replace_wrep_post_nonum,\n",
    "    rm_brackets,\n",
    "    rm_useless_newlines,\n",
    "    rm_useless_spaces,\n",
    "    spec_add_spaces,\n",
    "    ungroup_emoji,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-favor",
   "metadata": {},
   "source": [
    "## Pre-processing \"Thai\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parallel-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset containing only reviews in Thai\n",
    "dataset_th_df = pd.read_csv('train_thai_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "auburn-seminar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39723, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_th_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-agreement",
   "metadata": {},
   "source": [
    "### General Preprocessing before Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enormous-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    \"\"\"\n",
    "    Preprocessing reviews\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove URLs\n",
    "    review = re.sub(r'http\\S+', '', review)\n",
    "    review = re.sub(r'www\\S+', '', review)\n",
    "    \n",
    "    # remove html tags\n",
    "    review = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # replace newlines with whitespace\n",
    "    review = review.replace('\\n', ' ')\n",
    "    \n",
    "    # remove multiple consecutive spaces\n",
    "    review = re.sub(' +', ' ', review)\n",
    "    \n",
    "    # strip() method removes whitespace, at the beginning and end (both sides) of a string\n",
    "    review = review.strip()\n",
    "    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply general pre-processing steps \n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(preprocess_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "local-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Text normalization from pythainlp.util.normalize\n",
    "\n",
    "Normalize and clean Thai text with normalizing rules as follows:\n",
    "* Remove zero-width spaces\n",
    "* Remove duplicate spaces\n",
    "* Reorder tone marks and vowels to standard order/spelling\n",
    "* Remove duplicate vowels and signs\n",
    "* Remove duplicate tone marks\n",
    "* Remove dangling non-base characters at the beginning of text\n",
    "\n",
    "--> normalizing the character order is required for the machine to understand the seemingly similar tokens\n",
    "\n",
    "Remove all Thai tone marks from the text from pythainlp.util.remove_tonemark\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(normalize)\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(remove_tonemark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "neutral-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Customized Preprocessing before Tokenization from pythainlp.ulmfit.preprocess\n",
    "\"\"\"\n",
    "\n",
    "# Replace html string in text\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(fix_html)\n",
    "\n",
    "# Replace repetitions at the character level in `text` after the repetition  'น้อยยยยยยยย' --> 'น้อย xxrep '\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(replace_rep_nonum)\n",
    "\n",
    "# Remove all empty brackets and artifacts within brackets from review\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(rm_brackets)\n",
    "\n",
    "# Remove multiple newlines in review\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(rm_useless_newlines)\n",
    "\n",
    "# Remove multiple spaces in review\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(rm_useless_spaces)\n",
    "\n",
    "# Add spaces around / and # in review\n",
    "dataset_th_df['Text'] = dataset_th_df['Text'].apply(spec_add_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nervous-endorsement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In an online environment, Thai people often express laughter in written language with the repetition of ‘5’ \n",
    "# there are no more than 3 consecutive ‘5’, otherwise - replaced all with a special token\n",
    "\n",
    "dataset_th_df[dataset_th_df.apply(lambda x: '5555' in x['Text'], axis=1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-investigation",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surrounded-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>นอกจากเป็นรานนำแข็งใสสไตล์เกาหลีแลว ยังมีเมนูเ...</td>\n",
       "      <td>[นอกจาก, เป็น, ราน, นำ, แข็ง, ใส, สไตล์, เกาหล...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>มือกลางวันวันนี เราแวะมาทานที Jewelry Trade Ce...</td>\n",
       "      <td>[มือ, กลางวัน, วัน, นี,  , เรา, แวะ, มา, ทา, น...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รานเล็กๆบนถนนนิมมาน ตังอยุปากซอยทางจะเขาไปประเ...</td>\n",
       "      <td>[ราน, เล็ก, ๆบน, ถนน, นิมมาน,  , ตัง, อ, ยุ, ป...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>แถวๆ เขือนปาสักฯ นันก็มีรานอาหารอยูหลายรานเลย ...</td>\n",
       "      <td>[แถวๆ,  , เขือ, น, ปา, สัก, ฯ,  , นัน, ก็, มี,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>เป็นรานอาหารชายทะเล มีอาหารทะเลสดๆใหกินทุกวัน ...</td>\n",
       "      <td>[เป็น, ราน, อาหาร, ชายทะเล,  , มี, อาหารทะเล, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>รานนีคอนขางจะเป็นรานทีมีชือเสียง ประมาณวาแขกไป...</td>\n",
       "      <td>[ราน, นี, คอน, ขาง, จะ, เป็น, รา, นที, มี, ชือ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  นอกจากเป็นรานนำแข็งใสสไตล์เกาหลีแลว ยังมีเมนูเ...   \n",
       "1  มือกลางวันวันนี เราแวะมาทานที Jewelry Trade Ce...   \n",
       "2  รานเล็กๆบนถนนนิมมาน ตังอยุปากซอยทางจะเขาไปประเ...   \n",
       "3  แถวๆ เขือนปาสักฯ นันก็มีรานอาหารอยูหลายรานเลย ...   \n",
       "4  เป็นรานอาหารชายทะเล มีอาหารทะเลสดๆใหกินทุกวัน ...   \n",
       "5  รานนีคอนขางจะเป็นรานทีมีชือเสียง ประมาณวาแขกไป...   \n",
       "\n",
       "                                          Text_token  \n",
       "0  [นอกจาก, เป็น, ราน, นำ, แข็ง, ใส, สไตล์, เกาหล...  \n",
       "1  [มือ, กลางวัน, วัน, นี,  , เรา, แวะ, มา, ทา, น...  \n",
       "2  [ราน, เล็ก, ๆบน, ถนน, นิมมาน,  , ตัง, อ, ยุ, ป...  \n",
       "3  [แถวๆ,  , เขือ, น, ปา, สัก, ฯ,  , นัน, ก็, มี,...  \n",
       "4  [เป็น, ราน, อาหาร, ชายทะเล,  , มี, อาหารทะเล, ...  \n",
       "5  [ราน, นี, คอน, ขาง, จะ, เป็น, รา, นที, มี, ชือ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyThaiNLP - Default word tokenizer (“newmm”) use maximum matching algorithm.\n",
    "dataset_th_df['Text_token'] = dataset_th_df['Text'].apply(word_tokenize)\n",
    "\n",
    "# show 5 samples\n",
    "dataset_th_df.loc[:5, ['Text','Text_token']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-diameter",
   "metadata": {},
   "source": [
    "### General Preprocessing after Tokenization\n",
    "\n",
    "General preprocessing techniques after tokenization were used. This includes ungrouping the emoji’s from text, and to lowercase all English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eligible-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all English words\n",
    "dataset_th_df['Text_token'] = dataset_th_df['Text_token'].apply(lowercase_all)\n",
    "\n",
    "# ungrouping the emoji’s from text\n",
    "dataset_th_df['Text_token'] = dataset_th_df['Text_token'].apply(ungroup_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "graduate-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>มาลองนำแข็งไสเกาหลี berry snow ผลไมเยอะมากรสเป...</td>\n",
       "      <td>3</td>\n",
       "      <td>[มา, ลอง, นำ, แข็ง, ไส, เกาหลี,  , berry,  , s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>รานนีบรรยากาศถือวานานังเลยทีเดียวแตราคาอาหารคอ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[ราน, นี, บรรยากาศ, ถือ, วา, นา, นัง, เลย, ทีเ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รานนีตังอยูในเขตของมหาลัยมหาสารคาม จอดรถไดตามข...</td>\n",
       "      <td>3</td>\n",
       "      <td>[ราน, นี, ตัง, อ, ยู, ใน, เขต, ของ, มหาลัย, มห...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>รานแหลมเจริญ รานอาหารชือดังทีขึนชือเรืองอาหารท...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ราน, แหลม, เจริญ,  , ราน, อาหาร, ชือ, ดัง, ที...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>รานนีอยูในหมูบานวิทยุการบิน ทางมาอาจจะลึกลับไป...</td>\n",
       "      <td>4</td>\n",
       "      <td>[ราน, นีอ, ยู, ใน, หมู, บาน, วิทยุ, การ, บิน, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Rating  \\\n",
       "0  มาลองนำแข็งไสเกาหลี berry snow ผลไมเยอะมากรสเป...       3   \n",
       "1  รานนีบรรยากาศถือวานานังเลยทีเดียวแตราคาอาหารคอ...       2   \n",
       "2  รานนีตังอยูในเขตของมหาลัยมหาสารคาม จอดรถไดตามข...       3   \n",
       "3  รานแหลมเจริญ รานอาหารชือดังทีขึนชือเรืองอาหารท...       5   \n",
       "4  รานนีอยูในหมูบานวิทยุการบิน ทางมาอาจจะลึกลับไป...       4   \n",
       "\n",
       "                                          Text_token  \n",
       "0  [มา, ลอง, นำ, แข็ง, ไส, เกาหลี,  , berry,  , s...  \n",
       "1  [ราน, นี, บรรยากาศ, ถือ, วา, นา, นัง, เลย, ทีเ...  \n",
       "2  [ราน, นี, ตัง, อ, ยู, ใน, เขต, ของ, มหาลัย, มห...  \n",
       "3  [ราน, แหลม, เจริญ,  , ราน, อาหาร, ชือ, ดัง, ที...  \n",
       "4  [ราน, นีอ, ยู, ใน, หมู, บาน, วิทยุ, การ, บิน, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle rows in the dataset\n",
    "dataset_th_df = dataset_th_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dataset_th_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "further-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed dataset to file\n",
    "dataset_th_df.to_csv('train_thai_processed_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
